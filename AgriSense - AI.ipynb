{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhZ-7y9jI-cC"
      },
      "source": [
        "##Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64JrveO_Gb5F"
      },
      "outputs": [],
      "source": [
        "# Colab cell 1\n",
        "!pip install -q kaggle tensorflow matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrEh4b3YJCdx"
      },
      "source": [
        "##Upload kaggle.json (Kaggle API token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ZCH-L80THkeS",
        "outputId": "cddc07f4-4aa4-4664-88d5-57c1fa099d5b"
      },
      "outputs": [],
      "source": [
        "# Colab cell 2 - run this and upload kaggle.json when prompted\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # choose kaggle.json from your machine\n",
        "\n",
        "# move to correct place and set permissions\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# confirm kaggle works\n",
        "!kaggle --version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHZ8OrRfJFrl"
      },
      "source": [
        "##Download + unzip the PlantVillage dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQqbTMroITiO",
        "outputId": "e0ca0c34-7062-46ba-ebcd-c88c6712b7c2"
      },
      "outputs": [],
      "source": [
        "# Colab cell 3 - download & unzip\n",
        "# Download dataset (slug: abdallahalidev/plantvillage-dataset)\n",
        "!kaggle datasets download -d abdallahalidev/plantvillage-dataset -p /content/\n",
        "\n",
        "# Unzip any downloaded zip(s) into /content/plant_dataset\n",
        "!mkdir -p /content/plant_dataset\n",
        "!unzip -q /content/*.zip -d /content/plant_dataset\n",
        "\n",
        "# Show top-level files/folders found\n",
        "!ls -la /content/plant_dataset | sed -n '1,120p'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Iseq40vJIYo"
      },
      "source": [
        "##Create a small sample dataset (3 largest classes) â€” quick training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8prSFUAIhoG",
        "outputId": "72f56449-b730-407b-ce2e-9d88997dc4d4"
      },
      "outputs": [],
      "source": [
        "# Colab cell 4 - create small subset (3 classes)\n",
        "import os, shutil, random\n",
        "from glob import glob\n",
        "random.seed(42)\n",
        "\n",
        "ORIG_ROOT = '/content/plant_dataset'\n",
        "SMALL_ROOT = '/content/plant_dataset_small'\n",
        "os.makedirs(SMALL_ROOT, exist_ok=True)\n",
        "\n",
        "# Find directories that contain images\n",
        "def find_image_dirs(root):\n",
        "    image_dirs = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        # consider only directories that have image files\n",
        "        if any(fname.lower().endswith(('.jpg','.jpeg','.png')) for fname in filenames):\n",
        "            # Check if the directory contains a significant number of images to be considered a class directory\n",
        "            if len([f for f in filenames if f.lower().endswith(('.jpg','.jpeg','.png'))]) > 10: # threshold of 10 images to consider it a class dir\n",
        "                image_dirs.append(dirpath)\n",
        "    return sorted(image_dirs)\n",
        "\n",
        "\n",
        "image_dirs = find_image_dirs(ORIG_ROOT)\n",
        "print(f\"Found {len(image_dirs)} possible image dirs. Sample: {image_dirs[:5]}\")\n",
        "\n",
        "# compute counts\n",
        "counts = []\n",
        "for d in image_dirs:\n",
        "    files = [f for f in os.listdir(d) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
        "    counts.append((d, len(files)))\n",
        "counts = sorted(counts, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# pick top N classes (change N to your liking)\n",
        "N = 3\n",
        "chosen = counts[:N]\n",
        "print(\"Chosen classes (path, count):\")\n",
        "for p,c in chosen:\n",
        "    print(os.path.basename(p), c)\n",
        "\n",
        "# create train/valid splits and copy files\n",
        "train_ratio = 0.8\n",
        "for class_path, cnt in chosen:\n",
        "    class_name = os.path.basename(class_path)\n",
        "    src_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
        "    random.shuffle(src_files)\n",
        "    split = int(train_ratio * len(src_files))\n",
        "    train_files = src_files[:split]\n",
        "    valid_files = src_files[split:]\n",
        "\n",
        "    train_dst = os.path.join(SMALL_ROOT, 'train', class_name)\n",
        "    valid_dst = os.path.join(SMALL_ROOT, 'valid', class_name)\n",
        "    os.makedirs(train_dst, exist_ok=True)\n",
        "    os.makedirs(valid_dst, exist_ok=True)\n",
        "\n",
        "    for fname in train_files:\n",
        "        shutil.copy(os.path.join(class_path, fname), os.path.join(train_dst, fname))\n",
        "    for fname in valid_files:\n",
        "        shutil.copy(os.path.join(class_path, fname), os.path.join(valid_dst, fname))\n",
        "\n",
        "print(\"Small dataset created at:\", SMALL_ROOT)\n",
        "!find /content/plant_dataset_small -maxdepth 2 -type d -print"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ61d6yqI4zL"
      },
      "source": [
        "##Data generators (uses MobileNetV2 preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcKs1lc6I2eR",
        "outputId": "d5403b74-e0c8-4697-ab0a-819f7da08617"
      },
      "outputs": [],
      "source": [
        "# Colab cell 5 - data generators\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "train_dir = '/content/plant_dataset_small/train'\n",
        "valid_dir = '/content/plant_dataset_small/valid'\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   rotation_range=20,\n",
        "                                   horizontal_flip=True,\n",
        "                                   zoom_range=0.15)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_gen = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClasywXQJLr3"
      },
      "source": [
        "##Build the model (MobileNetV2 transfer learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "Mz1Ddb6GJOEu",
        "outputId": "2c25ee8a-2883-429f-bb64-fe342d7eea68"
      },
      "outputs": [],
      "source": [
        "# Check number of classes in train_gen\n",
        "num_classes = train_gen.num_classes\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "# Then rebuild the model last layer\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(num_classes, activation='softmax')  # <- use num_classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSMOYL8mJTlh"
      },
      "source": [
        "##Train (fast: small number of epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shYhRE9DJ9IW",
        "outputId": "3ce1dbf3-2ade-492e-b044-6d55311aa896"
      },
      "outputs": [],
      "source": [
        "# Colab cell 7 - train\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "EPOCHS = 8\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hGrO7zRKNx_"
      },
      "source": [
        "##Plot accuracy & loss (Matplotlib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "Dmz0gbZhKQ2N",
        "outputId": "76d7f470-daaa-408c-a47f-e55437640b67"
      },
      "outputs": [],
      "source": [
        "# Colab cell 8 - plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAku0JTJLYMf"
      },
      "source": [
        "##Save / Load best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bOnYB9vLXd1",
        "outputId": "ff6a099d-7890-46de-f8ec-727162961ab3"
      },
      "outputs": [],
      "source": [
        "# Colab cell 9 - save/load\n",
        "model.save('plantshieldnet_mobilenet_full.h5')       # full model\n",
        "# To load later:\n",
        "# from tensorflow.keras.models import load_model\n",
        "# model = load_model('best_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEefqCcFLdBT"
      },
      "source": [
        "##Inference on a new image (upload & predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "wkLRhSWvLhxz",
        "outputId": "db1c2092-35ea-4974-8518-5b076786a157"
      },
      "outputs": [],
      "source": [
        "# Colab cell 10 - test on your image\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Upload an image from your computer\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "img = image.load_img(img_path, target_size=IMG_SIZE)\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# apply MobileNetV2 preprocess\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "x = preprocess_input(x)\n",
        "\n",
        "pred = model.predict(x)[0]\n",
        "pred_idx = int(np.argmax(pred))\n",
        "inv_map = {v:k for k,v in train_gen.class_indices.items()}\n",
        "print(\"Predicted class:\", inv_map[pred_idx])\n",
        "print(\"Confidence:\", float(np.max(pred)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yv9tyqsYHmP",
        "outputId": "903de4bf-8604-4bfe-d14f-eb2bf8e35959"
      },
      "outputs": [],
      "source": [
        "# Colab cell 11 - fine-tuning (optional)\n",
        "base_model.trainable = True\n",
        "# Fine-tune from this layer onwards (tweak)\n",
        "fine_tune_at = 100\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_fine = model.fit(train_gen, validation_data=valid_gen, epochs=5, callbacks=callbacks)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
